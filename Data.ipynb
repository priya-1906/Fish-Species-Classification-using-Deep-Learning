#  Import Libraries
import os
import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image

import tensorflow as tf
from tensorflow.keras import layers, models, Model, Input
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

from sklearn.metrics import classification_report, confusion_matrix
print("TensorFlow version:", tf.__version__)
---------------------------------------------------------------------------------------------------
# Dataset Loading

TRAIN_DIR = "/content/dataset/images.cv_jzk6llhf18tm3k0kyttxz/data/train"   
VAL_DIR   = "/content/dataset/images.cv_jzk6llhf18tm3k0kyttxz/data/val"
TEST_DIR  = "/content/dataset/images.cv_jzk6llhf18tm3k0kyttxz/data/test"

IMG_SIZE = (224, 224)
BATCH_SIZE = 32

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)
val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

# flow_from_directory will error if the path is wrong; check and adjust paths if necessary
train_ds = train_datagen.flow_from_directory(
    TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'
)
val_ds = val_datagen.flow_from_directory(
    VAL_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'
)
test_ds = test_datagen.flow_from_directory(
    TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False
)

class_names = list(train_ds.class_indices.keys())
print("Classes:", class_names)
print("Train batches:", len(train_ds), " Val batches:", len(val_ds), " Test batches:", len(test_ds))
---------------------------------------------------------------------------------------------------------------

# Model 1 — CNN Training

# Build CNN (simple)
cnn = models.Sequential([
    layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(len(class_names), activation='softmax')
])

cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cnn.summary()

# Train CNN (adjust epochs as needed)
cnn_ckpt = "/content/cnn_model.h5"
callbacks_cnn = [
    ModelCheckpoint(cnn_ckpt, monitor='val_accuracy', save_best_only=True, verbose=1),
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)
]

EPOCHS_CNN = 8
history_cnn = cnn.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS_CNN,
    callbacks=callbacks_cnn
)

# Save final CNN model (optional)
cnn.save("/content/cnn_model_final.keras")
print("Saved CNN final model.")

# Evaluate CNN on test set
import numpy as np
if os.path.exists("/content/cnn_model.h5"):
    cnn.load_weights("/content/cnn_model.h5")
preds = cnn.predict(test_ds, verbose=1)
y_pred = np.argmax(preds, axis=1)
y_true = test_ds.classes

print("CNN Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.xticks(rotation=45, ha='right')
plt.title("Confusion Matrix - CNN")
plt.show()
--------------------------------------------------------------------------------------------------------------------------
#  Model 2 — MobileNetV2 (head only)

IMG_SIZE = (224,224)
num_classes = len(class_names)

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
base_model.trainable = False

inputs = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
outputs = Dense(num_classes, activation='softmax')(x)
mobilenet_model = Model(inputs, outputs)

mobilenet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
                        loss='categorical_crossentropy', metrics=['accuracy'])
mobilenet_model.summary()

# Callbacks and checkpoint
CHECKPOINT_PATH = "/content/mobilenet_best.h5"
callbacks = [
    ModelCheckpoint(CHECKPOINT_PATH, monitor='val_accuracy', save_best_only=True, verbose=1),
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
]

EPOCHS_MOB = 8
history_mobilenet = mobilenet_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS_MOB,
    callbacks=callbacks
)

print("Training finished. Best weights saved to:", CHECKPOINT_PATH)

if os.path.exists(CHECKPOINT_PATH):
    mobilenet_model.load_weights(CHECKPOINT_PATH)
    mobilenet_model.save("/content/mobilenet_best_model.keras")
    mobilenet_model.save("/content/mobilenet_best_model.h5")
    print("Saved mobilenet_best_model.keras and mobilenet_best_model.h5")

---------------------------------------------------------------------------------------------------------------
# Fine-Tuning MobileNetV2

N = 50
base = mobilenet_model.layers[1]  # base model layer (MobileNetV2)
base.trainable = True
for layer in base.layers[:-N]:
    layer.trainable = False

mobilenet_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
                        loss='categorical_crossentropy', metrics=['accuracy'])

FT_CHECK = "/content/mobilenet_finetuned_best.h5"
callbacks_ft = [
    ModelCheckpoint(FT_CHECK, monitor='val_accuracy', save_best_only=True, verbose=1),
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)
]

EPOCHS_FT = 6
history_ft = mobilenet_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS_FT,
    callbacks=callbacks_ft
)

mobilenet_model.save("/content/mobilenet_finetuned.keras")
print("Saved fine-tuned model to /content/mobilenet_finetuned.keras")
------------------------------------------------------------------------------------------------------------------
# 7️Evaluation on TEST set (use the best available model)
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import csv

candidates = [
    "/content/mobilenet_finetuned.keras",
    "/content/mobilenet_finetuned_best.h5",
    "/content/mobilenet_best_model.keras",
    "/content/mobilenet_best.h5",
    "/content/cnn_model.h5",
    "/content/cnn_model_final.keras"
]

chosen = None
for p in candidates:
    if os.path.exists(p):
        chosen = p
        break
if chosen is None:
    raise FileNotFoundError("No model found among candidates. Please ensure a saved model is present.")

print("Using model:", chosen)
model = tf.keras.models.load_model(chosen, compile=True)

# Predictions
y_prob = model.predict(test_ds, verbose=1)
y_pred = np.argmax(y_prob, axis=1)
y_true = test_ds.classes

# Classification report
report = classification_report(y_true, y_pred, target_names=class_names, zero_division=0)
print("\nClassification Report:\n")
print(report)

from sklearn.metrics import precision_recall_fscore_support
prec, rec, f1, sup = precision_recall_fscore_support(y_true, y_pred, zero_division=0)
with open("/content/test_classification_report.csv", "w", newline='') as f:
    writer = csv.writer(f)
    writer.writerow(["class","precision","recall","f1-score","support"])
    for i,cn in enumerate(class_names):
        writer.writerow([cn, f"{prec[i]:.4f}", f"{rec[i]:.4f}", f"{f1[i]:.4f}", int(sup[i])])
print("Saved classification report CSV to: /content/test_classification_report.csv")

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(12,10))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.xticks(rotation=45, ha='right')
plt.ylabel('True'); plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.savefig("/content/confusion_matrix.png")
plt.show()
print("Saved confusion matrix image to: /content/confusion_matrix.png")

top3_acc = np.mean([y_true[i] in np.argsort(y_prob[i])[-3:] for i in range(len(y_true))])
print("Top-3 accuracy (approx):", top3_acc)
--------------------------------------------------------------------------------------------------------------------------
# Save artifacts
with open("/content/class_names.json", "w") as f:
    json.dump(class_names, f)
print("Saved /content/class_names.json")

final_candidates = ["/content/mobilenet_finetuned.keras", "/content/mobilenet_best_model.keras", "/content/final_model.keras"]
for p in final_candidates:
    if os.path.exists(p):
        # copy to canonical final path
        import shutil
        shutil.copy(p, "/content/final_model.keras")
        print("Copied", p, "-> /content/final_model.keras")
        break
-----------------------------------------------------------------------------------------------------------------------------------
# List artifacts
!ls -lh /content | sed -n '1,200p'
